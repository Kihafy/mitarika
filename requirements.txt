fastapi==0.115.2
uvicorn==0.34.2
gunicorn==23.0.0
python-multipart==0.0.12
numpy==1.26.4
Pillow==10.1.0
onnxruntime==1.15.0
onnx==1.17.0
requests==2.31.0
python-dotenv==1.0.1
pydantic==2.7.1
aiohttp==3.9.5
transformers==4.41.2  # Pour TinyLlama (fallback local)
torch==2.2.2  # Version CPU-only (Ã©conomise 200+ Mo de RAM)
