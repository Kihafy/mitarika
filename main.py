import io
import base64
from flask import Flask, request, jsonify
from PIL import Image
import numpy as np
import cv2
import emoji
import requests  # Pour utiliser l'API Hugging Face

app = Flask(__name__)

# Configuration pour √©conomiser la m√©moire
import onnxruntime as ort
ort.set_default_logger_severity(3)  # D√©sactive les logs inutiles

# 1. Compression d'image l√©g√®re (sans d√©pendances lourdes)
def light_compress(img, quality=30):
    """Compresse une image en JPEG avec OpenCV"""
    img_np = np.array(img)
    _, img_encoded = cv2.imencode('.jpg', img_np, [int(cv2.IMWRITE_JPEG_QUALITY), quality])
    return io.BytesIO(img_encoded.tobytes())

# 2. Base de connaissances simplifi√©e
PLANT_ADVICE = {
    "tomate": "üå± Arrosez mod√©r√©ment. Besoin de soleil direct.",
    "laitue": "ü™¥ Arrosage fr√©quent. Pousse √† l'ombre."
}

# 3. Utilisation d'un micro-mod√®le ONNX (ex: MobileNetV2 light)
# T√©l√©chargement au premier appel pour √©viter de charger en m√©moire au d√©marrage
MODEL_URL = "https://github.com/onnx/models/raw/main/vision/classification/mobilenet/model/mobilenetv2-7.onnx"

def get_model():
    """Charge le mod√®le seulement quand n√©cessaire"""
    session = ort.InferenceSession(MODEL_URL)
    return session

@app.route('/analyze', methods=['POST'])
def analyze():
    # V√©rification des donn√©es d'entr√©e
    if not request.json or 'image' not in request.json:
        return jsonify({"error": "Image data missing"}), 400

    try:
        # D√©codage de l'image
        img_b64 = request.json.get('image')
        img_bytes = base64.b64decode(img_b64)
        img = Image.open(io.BytesIO(img_bytes))
        
        # Compression
        compressed_img = light_compress(img)
        compressed_bytes = compressed_img.getvalue()
        
        # Diagnostic simplifi√© (simulation pour √©conomiser la m√©moire)
        # En production, utilisez l'API Hugging Face comme ci-dessous
        plant_type = request.json.get('plant', 'tomate')
        diagnosis = "‚úÖ Sain"  # Par d√©faut
        
        # Alternative r√©elle avec API Hugging Face (d√©commenter pour utiliser)
        # response = requests.post(
        #     "https://api-inference.huggingface.co/models/google/vit-base-patch16-224",
        #     headers={"Authorization": "Bearer VOTRE_CLE_API"},
        #     data=img_bytes
        # )
        # diagnosis = response.json()[0]['label']

        return jsonify({
            'diagnosis': diagnosis,
            'advice': emoji.emojize(PLANT_ADVICE.get(plant_type, "")),
            'compression_ratio': len(img_bytes)/len(compressed_bytes),
            'model_size': "0MB (API)",  # Aucun mod√®le charg√© localement
            'memory_usage': "~150MB"    # Estimation basse
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
